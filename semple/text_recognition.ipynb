{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Code source: dmitryelj@gmail.com\n",
    "\n",
    "import os\n",
    "# Force CPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# Debug messages\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "import tensorflow as tf\n",
    "from scipy import io as spio\n",
    "import idx2numpy  # sudo pip3 install idx2numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *\n",
    "import time\n",
    "\n",
    "\n",
    "# Dataset:\n",
    "# https://www.nist.gov/node/1298471/emnist-dataset\n",
    "# https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
    "\n",
    "\n",
    "def cnn_print_digit(d):\n",
    "    print(d.shape)\n",
    "    for x in range(28):\n",
    "        s = \"\"\n",
    "        for y in range(28):\n",
    "            s += \"{0:.1f} \".format(d[28*y + x])\n",
    "        print(s)\n",
    "\n",
    "\n",
    "def cnn_print_digit_2d(d):\n",
    "    print(d.shape)\n",
    "    for y in range(d.shape[0]):\n",
    "        s = \"\"\n",
    "        for x in range(d.shape[1]):\n",
    "            s += \"{0:.1f} \".format(d[x][y])\n",
    "        print(s)\n",
    "\n",
    "\n",
    "emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n",
    "\n",
    "\n",
    "def emnist_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def emnist_model2():\n",
    "    model = Sequential()\n",
    "    # In Keras there are two options for padding: same or valid. Same means we pad with the number on the edge and valid means no padding.\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "    ## model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def emnist_model3():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def emnist_train(model):\n",
    "    t_start = time.time()\n",
    "\n",
    "    emnist_path = '../data/gzip/'\n",
    "    X_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-images-idx3-ubyte')\n",
    "    y_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-labels-idx1-ubyte')\n",
    "\n",
    "    X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels))\n",
    "\n",
    "    # Test:\n",
    "    k = 10\n",
    "    X_train = X_train[:X_train.shape[0] // k]\n",
    "    y_train = y_train[:y_train.shape[0] // k]\n",
    "    X_test = X_test[:X_test.shape[0] // k]\n",
    "    y_test = y_test[:y_test.shape[0] // k]\n",
    "\n",
    "    # Normalize\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_train /= 255.0\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    X_test /= 255.0\n",
    "\n",
    "    x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))\n",
    "    y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))\n",
    "\n",
    "    # Set a learning rate reduction\n",
    "    learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "    model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30)\n",
    "    print(\"Training done, dT:\", time.time() - t_start)\n",
    "\n",
    "\n",
    "def emnist_predict(model, image_file):\n",
    "    img = keras.preprocessing.image.load_img(image_file, target_size=(28, 28), color_mode='grayscale')\n",
    "    emnist_predict_img(model, img)\n",
    "\n",
    "\n",
    "def emnist_predict_img(model, img):\n",
    "    img_arr = np.expand_dims(img, axis=0)\n",
    "    img_arr = 1 - img_arr/255.0\n",
    "    img_arr[0] = np.rot90(img_arr[0], 3)\n",
    "    img_arr[0] = np.fliplr(img_arr[0])\n",
    "    img_arr = img_arr.reshape((1, 28, 28, 1))\n",
    "\n",
    "    predict = model.predict([img_arr])\n",
    "    result = np.argmax(predict, axis=1)\n",
    "    return chr(emnist_labels[result[0]])\n",
    "\n",
    "\n",
    "def letters_extract(image_file: str, out_size=28):\n",
    "    img = cv2.imread(image_file)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "    # Get contours\n",
    "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    output = img.copy()\n",
    "\n",
    "    letters = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        # print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "        # hierarchy[i][0]: the index of the next contour of the same level\n",
    "        # hierarchy[i][1]: the index of the previous contour of the same level\n",
    "        # hierarchy[i][2]: the index of the first child\n",
    "        # hierarchy[i][3]: the index of the parent\n",
    "        if hierarchy[0][idx][3] == 0:\n",
    "            cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
    "            letter_crop = gray[y:y + h, x:x + w]\n",
    "            # print(letter_crop.shape)\n",
    "\n",
    "            # Resize letter canvas to square\n",
    "            size_max = max(w, h)\n",
    "            letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "            if w > h:\n",
    "                # Enlarge image top-bottom\n",
    "                # ------\n",
    "                # ======\n",
    "                # ------\n",
    "                y_pos = size_max//2 - h//2\n",
    "                letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
    "            elif w < h:\n",
    "                # Enlarge image left-right\n",
    "                # --||--\n",
    "                x_pos = size_max//2 - w//2\n",
    "                letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
    "            else:\n",
    "                letter_square = letter_crop\n",
    "\n",
    "            # Resize letter to 28x28 and add letter and its X-coordinate\n",
    "            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))\n",
    "\n",
    "    # Sort array in place by X-coordinate\n",
    "    letters.sort(key=lambda x: x[0], reverse=False)\n",
    "\n",
    "    # cv2.imshow(\"Input\", img)\n",
    "    # # cv2.imshow(\"Gray\", thresh)\n",
    "    # cv2.imshow(\"Enlarged\", img_erode)\n",
    "    # cv2.imshow(\"Output\", output)\n",
    "    # cv2.imshow(\"0\", letters[0][2])\n",
    "    # cv2.imshow(\"1\", letters[1][2])\n",
    "    # cv2.imshow(\"2\", letters[2][2])\n",
    "    # cv2.imshow(\"3\", letters[3][2])\n",
    "    # cv2.imshow(\"4\", letters[4][2])\n",
    "    cv2.waitKey(0)\n",
    "    return letters\n",
    "\n",
    "\n",
    "def img_to_str(model: Any, image_file: str):\n",
    "    letters = letters_extract(image_file)\n",
    "    s_out = \"\"\n",
    "    for i in range(len(letters)):\n",
    "        dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
    "        s_out += emnist_predict_img(model, letters[i][2])\n",
    "        if (dn > letters[i][1]/4):\n",
    "            s_out += ' '\n",
    "    return s_out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # model = emnist_model()\n",
    "    # emnist_train(model)\n",
    "    # model.save('emnist_letters.h5')\n",
    "\n",
    "    model = keras.models.load_model('emnist_letters.h5')\n",
    "    # s_out = img_to_str(model, \"hello_world.png\")\n",
    "    s_out = img_to_str(model, \"../data/test/test_e-sumbs.png\")\n",
    "\n",
    "    print(s_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# image_file = \"text.png\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m image_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/test/test_e-sumbs.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241m.\u001B[39mimread(image_file)\n\u001B[1;32m      4\u001B[0m gray \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(img, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2GRAY)\n\u001B[1;32m      5\u001B[0m ret, thresh \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mthreshold(gray, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m, cv2\u001B[38;5;241m.\u001B[39mTHRESH_BINARY)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# image_file = \"text.png\"\n",
    "image_file = \"../data/test/test_e-sumbs.png\"\n",
    "img = cv2.imread(image_file)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "# Get contours\n",
    "contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "output = img.copy()\n",
    "\n",
    "for idx, contour in enumerate(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    # print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "    # hierarchy[i][0]: the index of the next contour of the same level\n",
    "    # hierarchy[i][1]: the index of the previous contour of the same level\n",
    "    # hierarchy[i][2]: the index of the first child\n",
    "    # hierarchy[i][3]: the index of the parent\n",
    "    if hierarchy[0][idx][3] == 0:\n",
    "        cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Input\", img)\n",
    "cv2.imshow(\"Enlarged\", img_erode)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 20:09:40.502227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 20:09:40.598491: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-27 20:09:40.602730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-27 20:09:40.602746: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-27 20:09:40.624223: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-27 20:09:41.209897: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-27 20:09:41.210039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-27 20:09:41.210050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Code source: dmitryelj@gmail.com\n",
    "\n",
    "import os\n",
    "# Force CPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# Debug messages\n",
    "# 0 = all messages are logged (default behavior)\n",
    "# 1 = INFO messages are not printed\n",
    "# 2 = INFO and WARNING messages are not printed\n",
    "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "import cv2\n",
    "import imghdr\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.constraints import maxnorm\n",
    "import tensorflow as tf\n",
    "from scipy import io as spio\n",
    "import idx2numpy  # sudo pip3 install idx2numpy\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import *\n",
    "import time\n",
    "\n",
    "\n",
    "# Dataset:\n",
    "# https://www.nist.gov/node/1298471/emnist-dataset\n",
    "# https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip\n",
    "\n",
    "\n",
    "def cnn_print_digit(d):\n",
    "    print(d.shape)\n",
    "    for x in range(28):\n",
    "        s = \"\"\n",
    "        for y in range(28):\n",
    "            s += \"{0:.1f} \".format(d[28*y + x])\n",
    "        print(s)\n",
    "\n",
    "\n",
    "def cnn_print_digit_2d(d):\n",
    "    print(d.shape)\n",
    "    for y in range(d.shape[0]):\n",
    "        s = \"\"\n",
    "        for x in range(d.shape[1]):\n",
    "            s += \"{0:.1f} \".format(d[x][y])\n",
    "        print(s)\n",
    "\n",
    "\n",
    "emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]\n",
    "\n",
    "\n",
    "def emnist_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def emnist_model2():\n",
    "    model = Sequential()\n",
    "    # In Keras there are two options for padding: same or valid. Same means we pad with the number on the edge and valid means no padding.\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "    ## model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def emnist_model3():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def emnist_train(model):\n",
    "    t_start = time.time()\n",
    "\n",
    "    emnist_path = '../data/gzip/'\n",
    "    X_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-images-idx3-ubyte')\n",
    "    y_train = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-train-labels-idx1-ubyte')\n",
    "\n",
    "    X_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-images-idx3-ubyte')\n",
    "    y_test = idx2numpy.convert_from_file(emnist_path + 'emnist-byclass-test-labels-idx1-ubyte')\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 28, 28, 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 28, 28, 1))\n",
    "\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, len(emnist_labels))\n",
    "\n",
    "    # Test:\n",
    "    k = 10\n",
    "    X_train = X_train[:X_train.shape[0] // k]\n",
    "    y_train = y_train[:y_train.shape[0] // k]\n",
    "    X_test = X_test[:X_test.shape[0] // k]\n",
    "    y_test = y_test[:y_test.shape[0] // k]\n",
    "\n",
    "    # Normalize\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_train /= 255.0\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    X_test /= 255.0\n",
    "\n",
    "    x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))\n",
    "    y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))\n",
    "\n",
    "    # Set a learning rate reduction\n",
    "    learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "    model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=30)\n",
    "    print(\"Training done, dT:\", time.time() - t_start)\n",
    "\n",
    "\n",
    "def emnist_predict(model, image_file):\n",
    "    img = keras.preprocessing.image.load_img(image_file, target_size=(28, 28), color_mode='grayscale')\n",
    "    emnist_predict_img(model, img)\n",
    "\n",
    "\n",
    "def emnist_predict_img(model, img):\n",
    "    img_arr = np.expand_dims(img, axis=0)\n",
    "    img_arr = 1 - img_arr/255.0\n",
    "    img_arr[0] = np.rot90(img_arr[0], 3)\n",
    "    img_arr[0] = np.fliplr(img_arr[0])\n",
    "    img_arr = img_arr.reshape((1, 28, 28, 1))\n",
    "\n",
    "    predict = model.predict([img_arr])\n",
    "    result = np.argmax(predict, axis=1)\n",
    "    return chr(emnist_labels[result[0]])\n",
    "\n",
    "\n",
    "def letters_extract(image_file: str, out_size=28):\n",
    "    img = cv2.imread(image_file)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
    "    img_erode = cv2.erode(thresh, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "    # Get contours\n",
    "    contours, hierarchy = cv2.findContours(img_erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    output = img.copy()\n",
    "\n",
    "    letters = []\n",
    "    for idx, contour in enumerate(contours):\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "        # print(\"R\", idx, x, y, w, h, cv2.contourArea(contour), hierarchy[0][idx])\n",
    "        # hierarchy[i][0]: the index of the next contour of the same level\n",
    "        # hierarchy[i][1]: the index of the previous contour of the same level\n",
    "        # hierarchy[i][2]: the index of the first child\n",
    "        # hierarchy[i][3]: the index of the parent\n",
    "        if hierarchy[0][idx][3] == 0:\n",
    "            cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
    "            letter_crop = gray[y:y + h, x:x + w]\n",
    "            # print(letter_crop.shape)\n",
    "\n",
    "            # Resize letter canvas to square\n",
    "            size_max = max(w, h)\n",
    "            letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "            if w > h:\n",
    "                # Enlarge image top-bottom\n",
    "                # ------\n",
    "                # ======\n",
    "                # ------\n",
    "                y_pos = size_max//2 - h//2\n",
    "                letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
    "            elif w < h:\n",
    "                # Enlarge image left-right\n",
    "                # --||--\n",
    "                x_pos = size_max//2 - w//2\n",
    "                letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
    "            else:\n",
    "                letter_square = letter_crop\n",
    "\n",
    "            # Resize letter to 28x28 and add letter and its X-coordinate\n",
    "            letters.append((x, w, cv2.resize(letter_square, (out_size, out_size), interpolation=cv2.INTER_AREA)))\n",
    "\n",
    "    # Sort array in place by X-coordinate\n",
    "    letters.sort(key=lambda x: x[0], reverse=False)\n",
    "\n",
    "    # cv2.imshow(\"Input\", img)\n",
    "    # # cv2.imshow(\"Gray\", thresh)\n",
    "    # cv2.imshow(\"Enlarged\", img_erode)\n",
    "    # cv2.imshow(\"Output\", output)\n",
    "    # cv2.imshow(\"0\", letters[0][2])\n",
    "    # cv2.imshow(\"1\", letters[1][2])\n",
    "    # cv2.imshow(\"2\", letters[2][2])\n",
    "    # cv2.imshow(\"3\", letters[3][2])\n",
    "    # cv2.imshow(\"4\", letters[4][2])\n",
    "    cv2.waitKey(0)\n",
    "    return letters\n",
    "\n",
    "\n",
    "def img_to_str(model: Any, image_file: str):\n",
    "    letters = letters_extract(image_file)\n",
    "    s_out = \"\"\n",
    "    for i in range(len(letters)):\n",
    "        dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
    "        s_out += emnist_predict_img(model, letters[i][2])\n",
    "        if (dn > letters[i][1]/4):\n",
    "            s_out += ' '\n",
    "    return s_out\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.load_model('emnist_letters.h5')\n",
    "s_out = img_to_str(model, \"../data/test/test_e-sumbs.png\")\n",
    "print(s_out)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
